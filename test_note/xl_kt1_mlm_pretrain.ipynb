{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 보자!! 음 eos 토큰은 안쓰이는 숫자 여야 한다.\n",
    "\n",
    "\n",
    "concepts에 3~126이라 할때 \n",
    "response가 0,1이고 \n",
    "\n",
    "concepts도 eos가, response에도 eos가 있어야 하겠지?\n",
    "concepts+123*response = 이렇게 되면 기존에는 0~122 까지의 값에 0,123 이 더해지는 것이었잖아\n",
    "\n",
    "오답일 때 가질 수 있는 값은 0~122 \n",
    "정답일 떄 가질 수 있는 값은 123 ~225\n",
    "\n",
    "\n",
    "-----------------------------------------------------\n",
    "concepts을 3~125까지\n",
    "response를 0,1 이라 할때\n",
    "concepts+123*response =\n",
    "\n",
    "Interaction:\n",
    "오답일 때 가질 수 있는 값은 3~125 \n",
    "정답일 떄 가질 수 있는 값은 126 ~228\n",
    "\n",
    "Question:\n",
    "3~125\n",
    "\n",
    ";;;;;;;;;;;;\n",
    "eos =2 일때\n",
    "\n",
    "Interaction:\n",
    "오답일 때 가질 수 있는 값은 3~125 + eos 토큰끼리 더해졌을 때 4 추가 --> 곂침\n",
    "정답일 떄 가질 수 있는 값은 126 ~228 +eos 토큰끼리 더해졌을 때 4\n",
    "\n",
    "--> 이 경우 r에 더해진 eos값이 123이 곱해지며 또 달리 질 수 잇기에 r값에 eos를 더해주기 전에 미리 123(concept의)숫 자를 구한것을 따로 곱해두고 거기에 eos를 추가하자 \n",
    "r_shift경우 r을 두개로 만들어서 하나는 interaction용으로 빼두고 하나는 y값으로 쓰이게 eos만 추가해서 따로 두자!\n",
    "\n",
    "->거기다가 c,r에는 eos/2 를 더해 두개가 더해졌을 때 eos가 되도록 하고 \n",
    "c_shift, r_shift에는 온전한 eos를 더해두는 거지 그러면 문제 해결?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:27:05.676426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 16:27:06.206847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-18 16:27:06.206906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-18 16:27:06.206924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from preprocess.data_utils import read_data,get_max_concepts,calStatistics,extend_multi_concepts,id_mapping,save_id2idx,train_test_split,save_dcur,get_evalmask_token, get_mask_tokens\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from models.model_for_kt import TFTransfoXLModel,TFTransfoXLLMHeadModel,TFTransfoXLMLMHeadModel\n",
    "from tqdm import tqdm\n",
    "from transformers import TransfoXLConfig\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import datetime\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_xl = TransfoXLConfig(\n",
    "    data = '/home/jun/workspace/KT/data/ednet/data.txt',\n",
    "    dataset = 'wt103',\n",
    "    d_embed=128,\n",
    "    d_head = 32,\n",
    "    d_model=128,\n",
    "    mem_len=200,\n",
    "    n_head=8,\n",
    "    n_layer=6,\n",
    "    batch_size = 65,\n",
    "    tgt_len = 140,\n",
    "    ext_len = 0,\n",
    "    eval_tgt_len = 36,\n",
    "    eos_token=2,\n",
    "    num_c=123,\n",
    "    mask_token=3,\n",
    "    C_vocab_size=188,\n",
    "    Q_vocab_size = 12277,\n",
    "    R_vocab_size = 2,\n",
    "    epoch = 1,\n",
    "    tf_dir ='/home/jun/workspace/KT/data/ednet/TF_DATA',\n",
    "    mode = 'concepts' # questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete bad stu num of len: 7, delete interactions: 11, of r: 0, good num: 6162174\n",
      "====================\n",
      "original total interactions: 6162174, qs: 12102, cs: 188, seqnum: 4990\n",
      "df.columns: Index(['uid', 'is_repeat', 'concepts', 'timestamps', 'responses', 'usetimes',\n",
      "       'questions'],\n",
      "      dtype='object')\n",
      "====================\n",
      "after extend multi, total interactions: 15220330, qs: 12102, cs: 188, seqnum: 4990\n",
      "total num: 4990, train+valid num: 3992, test num: 998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ALL_KEYS = [\"fold\", \"uid\", \"questions\", \"concepts\", \"responses\", \"timestamps\",\n",
    "#             \"usetimes\", \"selectmasks\", \"is_repeat\", \"qidxs\", \"rest\", \"orirow\", \"cidxs\"]\n",
    "# ONE_KEYS = [\"fold\", \"uid\"]\n",
    "\n",
    "total_df, effective_keys = read_data('/home/jun/workspace/KT/data/ednet/data.txt')\n",
    "\n",
    "stares = []\n",
    "\n",
    "if 'concepts' in effective_keys:\n",
    "    max_concepts = get_max_concepts(total_df)\n",
    "else:\n",
    "    max_concepts = -1\n",
    "\n",
    "oris, _, qs, cs, seqnum = calStatistics(total_df, stares, \"original\") # Check data status\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\n",
    "    f\"original total interactions: {oris}, qs: {qs}, cs: {cs}, seqnum: {seqnum}\")\n",
    "\n",
    "\n",
    "# questions ,concepts 값들의 숫자를 재정의 하여 0~ 나오도록 만들 면서 is_repeat값 처리\n",
    "# 14_54_14 으로 된 concepts를 14,54,14 로 분리하고 기존의 response도 똑같이 확장처리\n",
    "total_df_ex, effective_keys = extend_multi_concepts(total_df, effective_keys)\n",
    "total_df, dkeyid2idx = id_mapping(total_df_ex)\n",
    "dkeyid2idx[\"max_concepts\"] = max_concepts\n",
    "\n",
    "extends, _, qs, cs, seqnum = calStatistics(\n",
    "    total_df, stares, \"extend multi\")\n",
    "print(\"=\"*20)\n",
    "print(\n",
    "    f\"after extend multi, total interactions: {extends}, qs: {qs}, cs: {cs}, seqnum: {seqnum}\")\n",
    "\n",
    "\n",
    "#train test 분리\n",
    "train_df, test_df = train_test_split(total_df, 0.2)\n",
    "\n",
    "#transformer_xl dataset 만들기\n",
    "train = {\"qseqs\": [], \"cseqs\": [], \"masked_R\": [], \"labels\": []} #\"q_shift\": [], \"c_shift\": [], \"r_shift\": []}\n",
    "test = {\"qseqs\": [], \"cseqs\": [], \"masked_R\": [], \"labels\": []} #\"q_shift\": [], \"c_shift\": [], \"r_shift\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:27:39.454610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.454944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.460372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.460717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.460898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.461165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.461857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 16:27:39.638491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.638814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.638990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.639245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.639405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:39.639657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.774236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.774567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.774746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.775001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.775161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.775401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6627 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-01-18 16:27:40.775693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 16:27:40.775833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 325 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# eos_token= 2 # config 파일로 조정할 수 있도록 수정 할 것!\n",
    "# num_c =123 # config 파일로 조정할 수 있도록 수정 할 것!\n",
    "for i, row in train_df.iterrows():\n",
    "#use kc_id or question_id as input\n",
    "\n",
    "    cseq_list=[int(_) for _ in row[\"concepts\"].split(\",\")]\n",
    "    cseq_list.append(config_xl.eos_token)\n",
    "    train[\"cseqs\"].append(cseq_list)\n",
    "\n",
    "    qes_list=[int(_) for _ in row[\"questions\"].split(\",\")]\n",
    "    qes_list.append(config_xl.eos_token)\n",
    "    train[\"qseqs\"].append(qes_list)\n",
    "\n",
    "\n",
    "    rseq_list=[(int(_)) for _ in row[\"responses\"].split(\",\")]\n",
    "    rseq_list.append(config_xl.eos_token)\n",
    "    masked_R, labels = get_mask_tokens(rseq_list,config_xl.mask_token, config_xl.eos_token)\n",
    "\n",
    "    train[\"masked_R\"].append(masked_R)\n",
    "    train[\"labels\"].append(labels)\n",
    "for i, row in test_df.iterrows():\n",
    "    #use kc_id or question_id as input\n",
    "    \n",
    "    cseq_list=[int(_) for _ in row[\"concepts\"].split(\",\")]\n",
    "    cseq_list.append(config_xl.eos_token)   \n",
    "    test[\"cseqs\"].append(cseq_list)\n",
    "\n",
    "    qes_list=[int(_) for _ in row[\"questions\"].split(\",\")]\n",
    "    qes_list.append(config_xl.eos_token)\n",
    "    test[\"qseqs\"].append(qes_list)\n",
    "\n",
    "\n",
    "    rseq_list=[(int(_)) for _ in row[\"responses\"].split(\",\")]\n",
    "    rseq_list.append(config_xl.eos_token)\n",
    "    masked_R, labels = get_evalmask_token(rseq_list, config_xl.mask_token, config_xl.eos_token)\n",
    "    \n",
    "\n",
    "    test[\"masked_R\"].append(masked_R)\n",
    "    test[\"labels\"].append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/gpu:0\"):\n",
    " #       with open('/home/jun/workspace/KT/data/ednet/train.pkl', \"rb\") as file:\n",
    "  #             train = pickle.load(file) \n",
    "               \n",
    "# with open('/home/jun/workspace/KT/data/ednet/test.pkl', \"rb\") as file:\n",
    "#         test = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "cseqs_list = list(itertools.chain(*train['cseqs']))\n",
    "qseqs_list = list(itertools.chain(*train['qseqs']))\n",
    "r_masked_list = tf.concat(train['masked_R'], axis=0)\n",
    "labels = tf.concat(train['labels'], axis=0)\n",
    "\n",
    "n_step = len(cseqs_list) // (config_xl.batch_size*config_xl.tgt_len)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sliced_cseqs = tf.slice(cseqs_list,[0],[n_step * config_xl.batch_size*config_xl.tgt_len])  \n",
    "sliced_qseqs = tf.slice(qseqs_list,[0],[n_step * config_xl.batch_size*config_xl.tgt_len])  \n",
    "sliced_r_mask = tf.slice(r_masked_list,[0],[n_step * config_xl.batch_size*config_xl.tgt_len]) \n",
    "sliced_labels = tf.slice(labels,[0],[n_step * config_xl.batch_size*config_xl.tgt_len]) \n",
    "\n",
    "count =len(sliced_cseqs)// (config_xl.batch_size*config_xl.tgt_len)\n",
    "\n",
    "new_shape = (config_xl.batch_size, -1)  # 나머지 차원은 자동으로 계산됨\n",
    "\n",
    "cseq_reshaped = tf.reshape(sliced_cseqs, new_shape)\n",
    "qseq_reshaped = tf.reshape(sliced_qseqs, new_shape)\n",
    "r_mask_reshaped = tf.reshape(sliced_r_mask, new_shape)\n",
    "labels_reshaped = tf.reshape(sliced_labels, new_shape)\n",
    "\n",
    "cseq_transposed = tf.transpose(cseq_reshaped)\n",
    "qseq_transposed = tf.transpose(qseq_reshaped)\n",
    "r_mask_transposed = tf.transpose(r_mask_reshaped)\n",
    "labels_transposed = tf.transpose(labels_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step 342\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test\n",
    "test_cseqs_list = list(itertools.chain(*test['cseqs']))\n",
    "test_qseqs_list = list(itertools.chain(*test['qseqs']))\n",
    "test_r_masked_list = tf.concat(test['masked_R'], axis=0)\n",
    "test_labels = tf.concat(test['labels'], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Work out how cleanly we can divide the dataset into bsz parts.\n",
    "# 아래의 두 코드는   data 텐서에서 배치 크기 bsz로 깔끔하게 맞지 않는 추가 요소를 제거하는 것 배치에 띡 떨어지게\n",
    "    \n",
    "test_n_step = len(test_cseqs_list) // (config_xl.batch_size*config_xl.tgt_len)\n",
    "print('n_step',test_n_step) # \n",
    "\n",
    "test_sliced_cseqs = tf.slice(test_cseqs_list,[0],[test_n_step * config_xl.batch_size*config_xl.tgt_len])  \n",
    "test_sliced_qseqs = tf.slice(test_qseqs_list,[0],[test_n_step * config_xl.batch_size*config_xl.tgt_len])  \n",
    "test_sliced_r_masked_seq = tf.slice(test_r_masked_list,[0],[test_n_step * config_xl.batch_size*config_xl.tgt_len]) \n",
    "\n",
    "test_sliced_labels = tf.slice(test_labels,[0],[test_n_step * config_xl.batch_size*config_xl.tgt_len])  \n",
    "\n",
    "count =len(test_sliced_cseqs)// (config_xl.batch_size*config_xl.tgt_len)\n",
    "print(count)\n",
    "\n",
    "'''# 시작 위치와 슬라이싱할 크기 설정\n",
    "begin = [0]  # 첫 번째 차원의 시작 위치는 0\n",
    "size = [6]   # 첫 번째 차원에서 6개의 원소를 슬라이싱\n",
    "\n",
    "# 데이터를 잘라내기 (tf.slice 사용)\n",
    "sliced_data = tf.slice(data, begin, size)  '''\n",
    "\n",
    "# Evenly divide the da\n",
    "# ta across the bsz batches.\n",
    "\n",
    "new_shape = (config_xl.batch_size, -1)  # 나머지 차원은 자동으로 계산됨\n",
    "\n",
    "test_qseq_reshaped = tf.reshape(test_sliced_qseqs, new_shape)\n",
    "test_cseq_reshaped = tf.reshape(test_sliced_cseqs, new_shape)\n",
    "test_r_masked_seq_reshaped = tf.reshape(test_sliced_r_masked_seq, new_shape)\n",
    "test_labels_reshaped = tf.reshape(test_sliced_labels, new_shape)\n",
    "\n",
    "\n",
    "test_qseq_reshaped = tf.transpose(test_qseq_reshaped)\n",
    "test_cseq_reshaped = tf.transpose(test_cseq_reshaped)\n",
    "test_r_masked_seq_reshaped = tf.transpose(test_r_masked_seq_reshaped)\n",
    "test_labels_reshaped = tf.cast(tf.transpose(test_labels_reshaped),tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (qseq_transposed,cseq_transposed, r_mask_transposed, labels_transposed))\n",
    "train_dataset =train_dataset.batch(config_xl.tgt_len)\n",
    "# tf.data.experimental.save(train_dataset, config_xl.tf_dir+'/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_qseq_reshaped,test_cseq_reshaped, test_r_masked_seq_reshaped, test_labels_reshaped))\n",
    "test_dataset =test_dataset.batch(config_xl.tgt_len)\n",
    "# tf.data.experimental.save(test_dataset, config_xl.tf_dir+'/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.experimental.load(config_xl.tf_dir+'/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = '/home/jun/workspace/KT/logs/gradient_tape/' + current_time +'{}ep_{}mem_Question/train'.format(config_xl.epoch, config_xl.mem_len)\n",
    "test_log_dir = '/home/jun/workspace/KT/logs/gradient_tape/' + current_time +'{}ep_{}mem_Question/test'.format(config_xl.epoch, config_xl.mem_len)\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = tf.cast(warmup_steps,tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step =tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'd_model': self.d_model,\n",
    "            'warmup_steps': self.warmup_steps\n",
    "            }\n",
    "learning_rate = CustomSchedule(config_xl.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTransfoXLMLMHeadModel(config=config_xl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='train_accuracy')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "  name='test_accuracy')\n",
    "test_precision = tf.metrics.Precision()\n",
    "test_recall = tf.metrics.Recall()\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "test_auc = tf.keras.metrics.AUC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, data1,data2, target, mems, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(concepts=data1,responses=data2, labels=target, mems=mems)\n",
    "        loss = outputs.loss\n",
    "        mems = outputs.mems\n",
    "        loss_mx = target != -100\n",
    "        loss_value = loss[loss_mx]\n",
    "        loss_value = tf.reshape(loss_value, [-1, config_xl.R_vocab_size])\n",
    "        labels = target[loss_mx]\n",
    "\n",
    "        \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=loss_value)\n",
    "        # batch_loss = tf.reduce_sum(loss) / valid_samples\n",
    "        mean_loss = tf.reduce_mean(loss)\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels,loss_value)\n",
    "        predictions =tf.nn.softmax(loss_value)\n",
    "        train_auc(tf.one_hot(labels, depth=predictions.shape[1]), predictions)\n",
    "\n",
    "    gradients = tape.gradient(mean_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "\n",
    "    return mems,mean_loss\n",
    "\n",
    "# def grad(model, inputs, targets):\n",
    "#   with tf.GradientTape() as tape:\n",
    "#     loss_value = loss(model, inputs, targets, training=True)\n",
    "#   return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, mems, test_dataset):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    evaluation_metrics = []\n",
    "    \n",
    "\n",
    "    for test_data1, test_data2, test_target in test_dataset:\n",
    "        outputs = model(concepts=test_data1, responses=test_data2, labels=test_target, mems=mems, training=False)\n",
    "        loss = outputs.loss\n",
    "        mems = outputs.mems\n",
    "\n",
    "        loss_mx = test_target != -100\n",
    "        loss_value = loss[loss_mx]\n",
    "        loss_value = tf.reshape(loss_value, [-1, config_xl.R_vocab_size])\n",
    "        labels = test_target[loss_mx]\n",
    "\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=loss_value)\n",
    "        mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # Update precision and recall metrics\n",
    "        predicted_labels = tf.argmax(loss_value, axis=1)\n",
    "        predictions =tf.nn.softmax(loss_value)\n",
    "\n",
    "        \n",
    "        test_auc(tf.one_hot(labels, depth=predictions.shape[1]), predictions)\n",
    "        test_precision(labels, predicted_labels)\n",
    "        test_recall(labels, predicted_labels)\n",
    "\n",
    "        test_accuracy(labels, loss_value)\n",
    "        test_loss(loss)\n",
    "        \n",
    "        \n",
    "        precision = test_precision.result().numpy()\n",
    "        recall = test_recall.result().numpy()\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "        evaluation_metrics.append(test_accuracy.result().numpy())\n",
    "\n",
    "        total_loss += mean_loss.numpy()\n",
    "        num_batches += 1\n",
    "\n",
    "        \n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=num_batches)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=num_batches)\n",
    "            tf.summary.scalar('precision', test_precision.result(), step=num_batches)\n",
    "            tf.summary.scalar('recall', test_recall.result(), step=num_batches)\n",
    "            tf.summary.scalar('f1_score', f1_score, step=num_batches)\n",
    "            tf.summary.scalar('auc', test_auc.result(), step=num_batches)\n",
    "\n",
    "    # 평균 정밀도, 재현율, F1 점수를 계산합니다.\n",
    "    average_precision = test_precision.result().numpy()\n",
    "    average_recall = test_recall.result().numpy()\n",
    "    average_f1_score = 2 * (average_precision * average_recall) / (average_precision + average_recall + 1e-7)\n",
    "\n",
    "    average_metric = sum(evaluation_metrics) / len(evaluation_metrics)\n",
    "    average_loss = total_loss / num_batches\n",
    "\n",
    "    return average_loss, average_metric, average_precision, average_recall, average_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n",
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n",
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n",
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:28:15.533935: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x5572443c0a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-18 16:28:15.533953: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-01-18 16:28:15.533972: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-01-18 16:28:15.537433: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-18 16:28:15.615873: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  0%|          | 1/1331 [00:12<4:36:19, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n",
      "func <class 'method'>\n",
      "config <class 'transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig'>\n",
      "kwargs <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1331 [00:19<41:59,  1.91s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb 셀 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m mems, loss_value \u001b[39m=\u001b[39m train_step(model, input_data,mask, labels, mems, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_value\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m num_batches \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/KT/xl_kt1_mlm_pretrain.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     loss_values\u001b[39m.\u001b[39mappend(loss_value\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1122\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "num_batches = 0\n",
    "# tf.summary.trace_on(graph=True, profiler=True)\n",
    "\n",
    "for epoch in range(config_xl.epoch):\n",
    "    start = time.time()\n",
    "    total_loss = 0.0\n",
    "    mems = None              # 첫 번째 모델의 메모리 상태\n",
    "           \n",
    "    for question,ceq, mask, labels in tqdm(train_dataset):\n",
    "        input_data = ceq if config_xl.mode == 'concepts' else question\n",
    "        mems, loss_value = train_step(model, input_data,mask, labels, mems, optimizer)\n",
    "        num_batches += 1\n",
    "        total_loss += loss_value.numpy()\n",
    "        if num_batches % 100 == 0:\n",
    "            loss_values.append(loss_value.numpy())\n",
    "            print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss_value.numpy()}')\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=num_batches)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=num_batches)\n",
    "            tf.summary.scalar('auc', train_auc.result(), step=num_batches)\n",
    "\n",
    "    # with writer.as_default():# 텐서보드에 모델 그래프 그리기\n",
    "    #     tf.summary.trace_export(\n",
    "    #         name=\"my_func_trace\",\n",
    "    #         step=0,\n",
    "    #         profiler_outdir=logdir)             \n",
    "\n",
    "    # Reset metrics every epoch\n",
    "    # train_loss.reset_states()\n",
    "    # test_loss.reset_states()\n",
    "    # train_accuracy.reset_states()\n",
    "    # test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mems = None\n",
    "# test_loss0,test_acc0,average_precision, average_recall, average_f1_score = evaluate(model,test_mems, test_dataset)\n",
    "# print(f'Test Loss on First Half Dataset after Epoch {epoch + 1}: {test_loss0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"concepts\"] {'mems': None, 'head_mask': None, 'inputs_embeds': None, 'output_attentions': False, 'output_hidden_states': False, 'return_dict': True, 'training': False, 'concepts': <tf.Tensor 'args_0:0' shape=(None, 65) dtype=int32>, 'responses': <tf.Tensor 'responses:0' shape=(None, 65) dtype=int32>, 'labels': None}\n",
      "inputs Tensor(\"args_0:0\", shape=(None, 65), dtype=int32)\n",
      "inputs[\"concepts\"] {'mems': None, 'head_mask': None, 'inputs_embeds': None, 'output_attentions': False, 'output_hidden_states': False, 'return_dict': True, 'training': False, 'concepts': <tf.Tensor 'concepts:0' shape=(None, 65) dtype=int32>, 'responses': <tf.Tensor 'responses:0' shape=(None, 65) dtype=int32>, 'labels': None}\n",
      "input_concepts Tensor(\"strided_slice:0\", shape=(65,), dtype=int32)\n",
      "inputs Tensor(\"Reshape:0\", shape=(1, 65), dtype=int32)\n",
      "input_concepts Tensor(\"strided_slice:0\", shape=(65,), dtype=int32)\n",
      "inputs Tensor(\"Reshape:0\", shape=(1, 65), dtype=int32)\n",
      "inputs[\"concepts\"] {'mems': None, 'head_mask': None, 'inputs_embeds': None, 'output_attentions': False, 'output_hidden_states': False, 'return_dict': True, 'training': True, 'concepts': <tf.Tensor 'concepts:0' shape=(None, 65) dtype=int32>, 'responses': <tf.Tensor 'responses:0' shape=(None, 65) dtype=int32>, 'labels': None}\n",
      "inputs[\"concepts\"] {'mems': None, 'head_mask': None, 'inputs_embeds': None, 'output_attentions': False, 'output_hidden_states': False, 'return_dict': True, 'training': False, 'input_ids': <tf.Tensor 'input_ids:0' shape=(None, None) dtype=int32>, 'concepts': None, 'responses': None, 'labels': None}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/jun/workspace/KT/models/model_for_kt.py\", line 1335, in serving  *\n        output = self.call(inputs)\n    File \"/home/jun/workspace/KT/models/model_for_kt.py\", line 1802, in call  *\n        bsz, tgt_len = shape_list(inputs[\"inputs_embeds\"])[:2]\n    File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/transformers/tf_utils.py\", line 39, in shape_list  *\n        dynamic = tf.shape(tensor)\n\n    ValueError: None values not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.save_weights('/home/jun/workspace/KT/save_model/5ep_600mem_questiion.ckpt/my_checkpoint') \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jun/workspace/KT/save_model/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model.load_weights('/home/jun/workspace/KT/save_model/5ep_600mem.ckpt/my_checkpoint')\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filec5t1dogc.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__serving\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcall, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileipoc4d1d.py:26\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, concepts, responses, mems, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m bsz \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbsz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m tgt_len \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtgt_len\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt((ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcepts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), if_body, else_body, get_state, set_state, (), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtransformer, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcepts\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmems\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead_mask\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m]), fscope)\n\u001b[1;32m     28\u001b[0m last_hidden \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(transformer_outputs)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileipoc4d1d.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[0;32m---> 23\u001b[0m     (bsz, tgt_len) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs_embeds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filebhvn_w7c.py:61\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__shape_list\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     59\u001b[0m static \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m dynamic \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28misinstance\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(tensor), ag__\u001b[38;5;241m.\u001b[39mld(np)\u001b[38;5;241m.\u001b[39mndarray), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filebhvn_w7c.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__shape_list.<locals>.else_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_1\u001b[39m():\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m retval_, do_return\n\u001b[0;32m---> 30\u001b[0m     dynamic \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (do_return, retval_)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/jun/workspace/KT/models/model_for_kt.py\", line 1335, in serving  *\n        output = self.call(inputs)\n    File \"/home/jun/workspace/KT/models/model_for_kt.py\", line 1802, in call  *\n        bsz, tgt_len = shape_list(inputs[\"inputs_embeds\"])[:2]\n    File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/transformers/tf_utils.py\", line 39, in shape_list  *\n        dynamic = tf.shape(tensor)\n\n    ValueError: None values not supported.\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('/home/jun/workspace/KT/save_model/5ep_600mem_questiion.ckpt/my_checkpoint') \n",
    "# model.save('/home/jun/workspace/KT/save_model/test')\n",
    "\n",
    "# model.load_weights('/home/jun/workspace/KT/save_model/5ep_600mem.ckpt/my_checkpoint')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 배치 크기를 가변적으로 처리하려면 첫 번째 차원을 None으로 두고,\n",
    "tensor = tf.keras.Input(shape=(2,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(tensor.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6319265374314715\n",
      "0.6484004206824721\n",
      "0.7520016045546908\n"
     ]
    }
   ],
   "source": [
    "print(test_loss0)\n",
    "print(test_acc0)\n",
    "print(average_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###임베딩 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "log_dir='/home/jun/workspace/KT/logs/question/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "  for concepts in dkeyid2idx['questions']:\n",
    "    f.write(\"{}\\n\".format(concepts))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(model.transformer.word_emb_C.get_weights()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jun/workspace/KT/logs/question/embedding.ckpt-1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir /logs/imdb-example/  실행코드\n",
    "#체크포인트 저장하는 방법 공부해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# Sample function to demonstrate the use of inspect.signature\n",
    "def sample_function(arg1, arg2=\"default\", *args, **kwargs):\n",
    "    print(\"Sample Function Executed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=dict(inspect.signature(sample_function).parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=A.pop('arg1',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Parameter \"arg1\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    if i % 2 ==0:\n",
    "        i+100\n",
    "    else:\n",
    "        i+10\n",
    "    \n",
    "    A=i+1\n",
    "\n",
    "    print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
