{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 18:59:04.371087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 18:59:04.888615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-15 18:59:04.888662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-15 18:59:04.888667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from KT.preprocess.data_utils import read_data,get_max_concepts,calStatistics,extend_multi_concepts,id_mapping,save_id2idx,train_test_split,save_dcur,generate_sequences, get_mask_tokens\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from KT.models.model_for_kt import TFTransfoXLModel,TFTransfoXLLMHeadModel,TFTransfoXLMLMHeadModel\n",
    "\n",
    "from transformers import TransfoXLConfig\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import datetime\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_xl = TransfoXLConfig(\n",
    "    data = '/home/jun/workspace/KT/data/ednet/data.txt',\n",
    "    dataset = 'wt103',\n",
    "    d_embed=128,\n",
    "    d_head = 32,\n",
    "    d_model=128,\n",
    "    mem_len=400,\n",
    "    n_head=8,\n",
    "    n_layer=6,\n",
    "    batch_size = 1,\n",
    "    tgt_len = 140,\n",
    "    ext_len = 0,\n",
    "    eval_tgt_len = 36,\n",
    "    eos_token=2,\n",
    "    num_c=123,\n",
    "    mask_token=3,\n",
    "    C_vocab_size=188,\n",
    "    R_vocab_size = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 18:59:06.954103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:06.959108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:06.959469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:06.960204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 18:59:06.960863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:06.961160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:06.961444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:07.348322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:07.348664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:07.348940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 18:59:07.349190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6336 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f68896aa520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFTransfoXLMLMHeadModel(config=config_xl)\n",
    "model.load_weights('/home/jun/workspace/KT/save_model/6ep_600mem.ckpt/my_checkpoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file_path = '/home/jun/workspace/KT/data/ednet/test_mapping.csv' # 이 값을 사용자가 넣을 수 있도록 하자\n",
    "\n",
    "df= pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = df.loc[df['uid'] == 3600, 'questions']\n",
    "concepts_list = df.loc[df['uid'] == 3600, 'concepts']\n",
    "responses_list = df.loc[df['uid'] == 3600, 'responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [int(x) for x in question_list[0].split(',')]\n",
    "concepts_list = [int(x) for x in concepts_list[0].split(',')]\n",
    "responses_list = [int(x) for x in responses_list[0].split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_R, labels = get_mask_tokens(responses_list,config_xl.mask_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(280,), dtype=int32, numpy=\n",
       "array([1, 0, 1, 1, 0, 0, 0, 1, 0, 3, 1, 1, 1, 1, 0, 0, 1, 0, 3, 3, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3,\n",
       "       1, 1, 1, 3, 0, 0, 3, 0, 0, 0, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 3,\n",
       "       3, 3, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       3, 3, 1, 3, 3, 0, 3, 0, 1, 3, 0, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 3, 0, 0, 0, 1, 1, 3, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 0, 0, 1, 3, 1, 0, 1, 3, 3, 0, 1,\n",
       "       1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 1, 1, 0, 1, 1, 3, 1, 1, 1, 1, 3, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 3, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 여기서 읽어온 데이터를 딕셔너리키 가지고 변환해서 ip mapping 하고 \n",
    "\n",
    "n_step = len(concepts_list) // (config_xl.tgt_len)\n",
    "\n",
    "sliced_qseqs = tf.slice(question_list,[0],[n_step *config_xl.tgt_len])  \n",
    "sliced_cseqs = tf.slice(concepts_list,[0],[n_step *config_xl.tgt_len])  \n",
    "sliced_masked_R = tf.slice(masked_R,[0],[n_step *config_xl.tgt_len]) \n",
    "sliced_labels = tf.slice(labels,[0],[n_step *config_xl.tgt_len]) \n",
    "\n",
    "\n",
    "new_shape = (config_xl.batch_size, -1)  # 나머지 차원은 자동으로 계산됨\n",
    "\n",
    "qseq_reshaped = tf.reshape(sliced_qseqs, new_shape)\n",
    "cseq_reshaped = tf.reshape(sliced_cseqs, new_shape)\n",
    "masked_R_reshaped = tf.reshape(sliced_masked_R, new_shape)\n",
    "labels_reshaped = tf.reshape(sliced_labels, new_shape)\n",
    "\n",
    "\n",
    "qseq_transposed = tf.transpose(qseq_reshaped)\n",
    "cseq_transposed = tf.transpose(cseq_reshaped)\n",
    "masked_R_transposed = tf.transpose(masked_R_reshaped)\n",
    "labels_transposed = tf.transpose(labels_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (cseq_transposed, masked_R_transposed,labels_transposed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset =predict_dataset.batch(config_xl.tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(280,), dtype=int32, numpy=\n",
       "array([4860, 6211, 9250, 4461, 3240, 3133, 6966, 9852, 3535,  672, 1302,\n",
       "       3151, 6326, 1818, 1045, 1018, 1035, 4633, 3472,  670, 1041, 2115,\n",
       "       1375, 6743, 1170, 1169, 1168, 1171, 4669, 2153, 2155, 2152, 2154,\n",
       "       7403, 7403, 7403, 7403, 3380,   51,   51,   51,   50,   50,   50,\n",
       "         52,   52,   52, 2212, 2212, 2212, 2210, 2210, 2210, 2211, 2211,\n",
       "       2211, 1830, 1830, 1830, 1831, 1831, 1831, 1831, 1829, 1829, 1829,\n",
       "       1887, 1885, 1888, 1886, 3206, 3206, 3206, 3207, 3207, 3207, 3205,\n",
       "       3205, 3205,  264,  264,  264,  264, 5594, 5594, 5594, 5593, 5593,\n",
       "       5593, 5594, 5594, 5594, 5593, 5593, 5593, 5595, 5595, 5595, 3737,\n",
       "       3737, 3737, 3737, 3381, 3381, 3381, 3813, 3813, 3813, 3813,  949,\n",
       "         10,   19, 4853, 2498, 2132, 2134, 2133, 2135,  623,  621,  624,\n",
       "        622, 1169, 1170, 1168, 1171, 1867, 1866, 1865, 1868, 1906, 1906,\n",
       "       1907, 1907, 1905, 1905, 1908, 1908, 1856, 1856, 1853, 1853, 1854,\n",
       "       1854, 1855, 1855, 1197, 1197, 1198, 1198, 1196, 1196, 2642, 2641,\n",
       "       2643, 2644, 1167, 1167, 1166, 1166, 1164, 1164, 1165, 1165, 2136,\n",
       "       2136, 2137, 2137, 2139, 2139, 2138, 2138, 1871, 1872, 1870, 1869,\n",
       "       2399, 2397, 2400, 2398, 1881, 1881, 1884, 1884, 1882, 1882, 1883,\n",
       "       1883, 1179, 1178, 1176, 1177, 1887, 1885, 1888, 1886, 6155, 6153,\n",
       "       6154, 6152, 1980, 1980, 1978, 1978, 1979, 1979, 1977, 1977, 2255,\n",
       "       2256, 2253, 2254,  643,  643,  641,  641,  644,  644,  642,  642,\n",
       "       4378, 4375, 4376, 4377, 2254, 2253, 2256, 2255, 1977, 1977, 1980,\n",
       "       1980, 1978, 1978, 1979, 1979,   27,   27,   29,   29,   26,   26,\n",
       "         28,   28, 5873, 5872, 5871, 5874,  626,  628,  627,  625, 1884,\n",
       "       1884, 1881, 1881, 1882, 1882, 1883, 1883, 1181, 1181, 1180, 1180,\n",
       "       1183, 1183, 1182, 1182, 3442, 3443, 3444, 3445, 2152, 2153, 2155,\n",
       "       2154, 1902, 1901, 1903, 1904], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_qseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mems =None\n",
    "predictions = []\n",
    "for test_data1, test_data2, test_target in predict_dataset:\n",
    "        outputs = model(concepts=test_data1, responses=test_data2, labels=test_target, mems=mems)\n",
    "        loss = outputs.loss\n",
    "        mems = outputs.mems\n",
    "        \n",
    "        reshape = tf.reshape(loss, [-1, config_xl.R_vocab_size])\n",
    "        predicted_labels = tf.argmax(reshape, axis=1)\n",
    "        predictions.append(predicted_labels.numpy().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list = [item for sublist in predictions for item in sublist]\n",
    "flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(280,), dtype=int32, numpy=\n",
       "array([-100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100,    0,    1, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100,    0, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100,    1, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,    1,\n",
       "       -100, -100, -100,    1, -100, -100,    0, -100, -100, -100, -100,\n",
       "       -100, -100, -100,    1, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,\n",
       "          1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          1,    1, -100,    1,    0, -100,    0, -100, -100,    1, -100,\n",
       "          0, -100, -100,    1, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100,    0, -100, -100, -100, -100,\n",
       "       -100,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          1, -100,    1, -100, -100, -100, -100, -100, -100, -100,    0,\n",
       "       -100, -100, -100,    1, -100, -100, -100,    1,    1, -100, -100,\n",
       "       -100,    1, -100, -100,    0,    0, -100, -100,    0,    0, -100,\n",
       "       -100, -100, -100, -100,    1, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100,    1, -100, -100,\n",
       "       -100,    1, -100, -100, -100,    1,    1,    1, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100,    0, -100, -100], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(280,), dtype=int32, numpy=\n",
       "array([-100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100,    0,    1, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100,    0, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100,    1, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,    1,\n",
       "       -100, -100, -100,    1, -100, -100,    0, -100, -100, -100, -100,\n",
       "       -100, -100, -100,    1, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,\n",
       "          1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          1,    1, -100,    1,    0, -100,    0, -100, -100,    1, -100,\n",
       "          0, -100, -100,    1, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100,    0, -100, -100, -100, -100,\n",
       "       -100,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          1, -100,    1, -100, -100, -100, -100, -100, -100, -100,    0,\n",
       "       -100, -100, -100,    1, -100, -100, -100,    1,    1, -100, -100,\n",
       "       -100,    1, -100, -100,    0,    0, -100, -100,    0,    0, -100,\n",
       "       -100, -100, -100, -100,    1, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100,    1, -100, -100,\n",
       "       -100,    1, -100, -100, -100,    1,    1,    1, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100,    0, -100, -100], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(44,), dtype=int32, numpy=\n",
       "array([ 672, 3472,  670, 7403,   52, 1829, 1829, 1886, 3206,  264,  949,\n",
       "         10,   19, 1907, 1907, 1905, 1908, 1856, 1853, 1854, 1197, 1164,\n",
       "       2137, 2399, 2400, 1883, 1176, 1888, 1886, 6152, 1978, 1978, 1977,\n",
       "       1977,  643,  642, 1977,   26,  627, 1881, 1883, 1883, 1181, 1901],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(44,), dtype=int32, numpy=\n",
       "array([113, 101, 120,  49,  49,  43,   8,  26,   9, 132, 134,  12,  24,\n",
       "        30, 138,  29,  30,  30, 122,   4,  30,  30,  30,  25,  29,  30,\n",
       "        29,  29,  26,  29,  30,  29,  30,  25,  22,  30,  25,  30,  25,\n",
       "        30,  30,  10,  30, 114], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Question':sliced_qseqs,'Concepts':sliced_cseqs,'Responses':flattened_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6211</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9250</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4461</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3240</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3133</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6966</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9852</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3535</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>672</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1302</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3151</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6326</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1818</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1045</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1018</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1035</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4633</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3472</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>670</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1041</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2115</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1375</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6743</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1170</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1169</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1168</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1171</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4669</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2153</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2155</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2152</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2154</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7403</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7403</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7403</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7403</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3380</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2212</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2212</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2212</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Question  Concepts  Responses\n",
       "0       4860       121          1\n",
       "1       6211        27          1\n",
       "2       9250        31          1\n",
       "3       4461       110          1\n",
       "4       3240       114          1\n",
       "5       3133        26          1\n",
       "6       6966        10          1\n",
       "7       9852        57          1\n",
       "8       3535        35          1\n",
       "9        672       113          1\n",
       "10      1302         4          1\n",
       "11      3151       103          1\n",
       "12      6326       145          1\n",
       "13      1818       110          1\n",
       "14      1045       125          1\n",
       "15      1018       113          1\n",
       "16      1035       121          1\n",
       "17      4633        84          1\n",
       "18      3472       101          1\n",
       "19       670       120          1\n",
       "20      1041       122          1\n",
       "21      2115       123          0\n",
       "22      1375        94          1\n",
       "23      6743        57          1\n",
       "24      1170        16          1\n",
       "25      1169        23          1\n",
       "26      1168        25          1\n",
       "27      1171        29          1\n",
       "28      4669        57          1\n",
       "29      2153        29          1\n",
       "30      2155        26          1\n",
       "31      2152       114          1\n",
       "32      2154        27          1\n",
       "33      7403        55          1\n",
       "34      7403        98          0\n",
       "35      7403         8          0\n",
       "36      7403        49          0\n",
       "37      3380        57          1\n",
       "38        51        52          1\n",
       "39        51         9          1\n",
       "40        51        49          1\n",
       "41        50        51          1\n",
       "42        50         9          1\n",
       "43        50        49          1\n",
       "44        52        53          1\n",
       "45        52         9          1\n",
       "46        52        49          1\n",
       "47      2212        51          1\n",
       "48      2212         9          1\n",
       "49      2212        49          1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is 5 2\n"
     ]
    }
   ],
   "source": [
    "A = 5\n",
    "B=2\n",
    "print('this is {} {}'.format(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
