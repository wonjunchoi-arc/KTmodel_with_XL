{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 14:57:46.522908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 14:57:47.090269: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-31 14:57:47.090311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2024-01-31 14:57:47.090317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from models.model_for_kt import TFTransfoXLModel,TFTransfoXLLMHeadModel,TFTransfoXLMLMHeadModel\n",
    "from transformers import TransfoXLConfig\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import logging\n",
    "from tensorboard.plugins import projector\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 14:57:48.445252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.445631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.450159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.450466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.450755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.451038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.451719: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 14:57:48.586954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.587272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.587541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.587795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.588050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:48.588303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.167692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.168028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.168298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.168551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.168833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.169068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6627 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-01-31 14:57:49.169312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-31 14:57:49.169587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6627 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "# Set up train eval Metric\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "name='test_accuracy')\n",
    "test_precision = tf.metrics.Precision()\n",
    "test_recall = tf.metrics.Recall()\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "test_auc = tf.keras.metrics.AUC()\n",
    "\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_TFdataset(config_xl) :\n",
    "    tf_train_dir = config_xl.tf_data_dir+'/{}'.format(config_xl.mode)+'/train'\n",
    "    tf_test_dir = config_xl.tf_data_dir+'/{}'.format(config_xl.mode)+'/test'\n",
    "    train_dataset = tf.data.experimental.load(tf_train_dir)\n",
    "    test_dataset = tf.data.experimental.load(tf_test_dir)\n",
    "    with open(config_xl.tf_data_dir+\"/dkeyid2idx.pkl\", \"rb\") as file:\n",
    "        dkeyid2idx = pickle.load(file) \n",
    "    \n",
    "    return train_dataset,test_dataset,dkeyid2idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@register_keras_serializable()\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = tf.cast(warmup_steps,tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step =tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'd_model': self.d_model,\n",
    "            'warmup_steps': self.warmup_steps\n",
    "            }\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, data1,data2, target, mems, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(concepts=data1,responses=data2, labels=target, mems=mems)\n",
    "        logit = outputs.logit\n",
    "        mems = outputs.mems\n",
    "        logit_mx = target != -100\n",
    "        logit_value = logit[logit_mx]\n",
    "        logit_value = tf.reshape(logit_value, [-1, config_xl.R_vocab_size])\n",
    "        labels = target[logit_mx]\n",
    "\n",
    "        \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logit_value)\n",
    "        # batch_loss = tf.reduce_sum(loss) / valid_samples\n",
    "        mean_loss = tf.reduce_mean(loss)\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels,logit_value)\n",
    "        predictions =tf.nn.softmax(logit_value)\n",
    "        train_auc(tf.one_hot(labels, depth=predictions.shape[1]), predictions)\n",
    "\n",
    "    gradients = tape.gradient(mean_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return mems,mean_loss\n",
    "\n",
    "\n",
    "def evaluate(model,test_dataset,config_xl):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    evaluation_metrics = []\n",
    "    test_mems = None\n",
    "\n",
    "    for input_data, masked_responses, responses in tqdm(test_dataset, desc='eval'):\n",
    "\n",
    "        outputs = model(concepts=input_data, responses=masked_responses, labels=responses, mems=test_mems, training=False)\n",
    "        logit = outputs.logit\n",
    "        test_mems = outputs.mems\n",
    "\n",
    "        logit_mx = responses != -100\n",
    "        logit_value = logit[logit_mx]\n",
    "        logit_value = tf.reshape(logit_value, [-1, config_xl.R_vocab_size])\n",
    "        labels = responses[logit_mx]\n",
    "\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logit_value)\n",
    "        mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # Update precision and recall metrics\n",
    "        predicted_labels = tf.argmax(logit_value, axis=1)\n",
    "        predictions =tf.nn.softmax(logit_value)\n",
    "\n",
    "        \n",
    "        test_auc(tf.one_hot(labels, depth=predictions.shape[1]), predictions)\n",
    "        test_precision(labels, predicted_labels)\n",
    "        test_recall(labels, predicted_labels)\n",
    "\n",
    "        test_accuracy(labels, logit_value)\n",
    "        test_loss(loss)\n",
    "        \n",
    "        \n",
    "        precision = test_precision.result().numpy()\n",
    "        recall = test_recall.result().numpy()\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "        evaluation_metrics.append(test_accuracy.result().numpy())\n",
    "\n",
    "        total_loss += mean_loss.numpy()\n",
    "        num_batches += 1\n",
    "\n",
    "        mlflow.log_metric('loss', test_loss.result(), step=num_batches)\n",
    "        mlflow.log_metric('accuracy', test_accuracy.result(), step=num_batches)\n",
    "        mlflow.log_metric('precision', test_precision.result(), step=num_batches)\n",
    "        mlflow.log_metric('recall', test_recall.result(), step=num_batches)\n",
    "        mlflow.log_metric('f1_score', f1_score, step=num_batches)\n",
    "        mlflow.log_metric('auc', test_auc.result(), step=num_batches)\n",
    "\n",
    "    # 평균 정밀도, 재현율, F1 점수를 계산합니다.\n",
    "    average_precision = test_precision.result().numpy()\n",
    "    average_recall = test_recall.result().numpy()\n",
    "    average_f1_score = 2 * (average_precision * average_recall) / (average_precision + average_recall + 1e-7)\n",
    "\n",
    "    average_metric = sum(evaluation_metrics) / len(evaluation_metrics)\n",
    "    average_loss = total_loss / num_batches\n",
    "\n",
    "    return average_loss, average_metric, average_precision, average_recall, average_f1_score\n",
    "\n",
    "# make embedding projector \n",
    "def Make_embedding_projector(model,config_xl, dkeyid2idx,):\n",
    "    log_dir=config_xl.tensorboard_emb_log_dir+'/'+current_time+'_{}ep_{}mem_{}/'.format(config_xl.epoch, config_xl.mem_len, config_xl.mode)\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # Save Labels separately on a line-by-line manner.\n",
    "    with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "        for valeu_before_mapping in dkeyid2idx[config_xl.mode]:\n",
    "            f.write(\"{}\\n\".format(valeu_before_mapping))\n",
    "\n",
    "    weights = tf.Variable(model.transformer.word_emb_C.get_weights()[0])\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "    # Set up config.\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    # The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'metadata.tsv'\n",
    "    projector.visualize_embeddings(log_dir, config)\n",
    "\n",
    "\n",
    "\n",
    "def train(train_dataset,config_xl):\n",
    "    try:\n",
    "        learning_rate = CustomSchedule(config_xl.d_model)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "        model = TFTransfoXLMLMHeadModel(config=config_xl)\n",
    "\n",
    "        loss_values = []\n",
    "        num_batches = 0\n",
    "\n",
    "        for epoch in range(config_xl.epoch):\n",
    "            start = time.time()\n",
    "            total_loss = 0.0\n",
    "            mems = None                   \n",
    "            for input_data, masked_responses, responses in tqdm(train_dataset, desc='train'):\n",
    "                mems, loss_value = train_step(model, input_data,masked_responses, responses, mems, optimizer)\n",
    "                num_batches += 1\n",
    "                total_loss += loss_value.numpy()\n",
    "                if num_batches % 100 == 0:\n",
    "                    loss_values.append(loss_value.numpy())\n",
    "                    print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss_value.numpy()}')\n",
    "                    mlflow.log_metric('loss', train_loss.result(), step=num_batches)\n",
    "                    mlflow.log_metric('accuracy', train_accuracy.result(), step=num_batches)\n",
    "                    mlflow.log_metric('auc', train_auc.result(), step=num_batches)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_499145/3063179905.py:23: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_499145/3063179905.py:23: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlen 600\n",
      "qlen 140\n",
      "mlen 600\n",
      "qlen 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 14:57:56.917507: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x56157302b000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-31 14:57:56.917523: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-01-31 14:57:56.917526: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-01-31 14:57:56.920892: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-31 14:57:56.997951: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "train: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/jun/workspace/KT/mlruns/804073929393319485', creation_time=1706512695084, experiment_id='804073929393319485', last_update_time=1706512695084, lifecycle_stage='active', name='MLflow Quickstart', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "config_xl = TransfoXLConfig(\n",
    "    d_embed=128,\n",
    "    d_head = 32,\n",
    "    d_model=128,\n",
    "    mem_len=600,\n",
    "    n_head=8,\n",
    "    n_layer=6,\n",
    "    mask_token=3,\n",
    "    C_vocab_size=188,\n",
    "    Q_vocab_size = 12277,\n",
    "    R_vocab_size = 2,\n",
    "    epoch = 1,\n",
    "    mode ='concepts', # concepts or questions \n",
    "    tf_data_dir ='/home/jun/workspace/KT/data/ednet/100_sam' ,\n",
    "    tensorboard_emb_log_dir = '/home/jun/workspace/KT/logs/embedding/',\n",
    ")\n",
    "\n",
    "train_dataset,test_dataset,dkeyid2idx=load_TFdataset(config_xl)\n",
    "model =train(train_dataset.take(1),config_xl)\n",
    "\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('save_model/my_model',from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /home/jun/workspace/KT/save_model/my_model were not used when initializing TFTransfoXLMLMHeadModel: ['transformer/dense/kernel:0', 'transformer/layer_normalization/beta:0', 'transformer/layer_normalization/gamma:0', 'transformer/embedding_1/embeddings:0', 'transformer/dense/bias:0', 'transformer/embedding/embeddings:0', 'transformer/dense_1/kernel:0']\n",
      "- This IS expected if you are initializing TFTransfoXLMLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFTransfoXLMLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFTransfoXLMLMHeadModel were not initialized from the model checkpoint at /home/jun/workspace/KT/save_model/my_model and are newly initialized: ['transformer/dense_3/kernel:0', 'transformer/layer_normalization_1/gamma:0', 'transformer/layer_normalization_1/beta:0', 'transformer/embedding_3/weight:0', 'transformer/dense_2/bias:0', 'transformer/embedding_2/weight:0', 'transformer/dense_2/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlen 600\n",
      "qlen 1\n"
     ]
    }
   ],
   "source": [
    "model = TFTransfoXLMLMHeadModel.from_pretrained(\"/home/jun/workspace/KT/save_model/my_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Start an MLflow run\n",
    "# with mlflow.start_run():\n",
    "#     # Log the hyperparameters\n",
    "#     mlflow.log_params(config_xl.to_dict())\n",
    "\n",
    "    \n",
    "#     test_loss,test_acc,test_precision, test_recall, test_f1_score = evaluate(model, test_dataset,config_xl)\n",
    "#     Make_embedding_projector(model,config_xl,dkeyid2idx)\n",
    "#     logging.info('test_loss:{},test_acc:{},test_precision:{}, test_recall:{}, test_f1_score:{}'.format(test_loss,test_acc,test_precision, test_recall, test_f1_score))\n",
    "    \n",
    "#     # Infer the model signature\n",
    "#     infer_mem = None\n",
    "#     input_data, masked_responses, responses = next(iter(train_dataset))\n",
    "#     outputs = model(concepts=input_data, responses=masked_responses, labels=responses, mems=infer_mem, training=False)\n",
    "#     logit = outputs.logit\n",
    "#     logit_value = tf.reshape(logit, [-1, config_xl.R_vocab_size])\n",
    "#     predicted_labels = tf.argmax(logit_value, axis=1)\n",
    "\n",
    "#     transposed_input = tf.transpose(input_data)\n",
    "#     transposed_response = tf.transpose(masked_responses)\n",
    "#     # 모델 입력과 출력에 대한 TensorSpec 정의\n",
    "#     input_schema = Schema(\n",
    "#     [\n",
    "#         TensorSpec(np.dtype(np.int32), (-1,len(transposed_input[0].numpy())), \"input_data\"),\n",
    "#         TensorSpec(np.dtype(np.int32), (-1,len(transposed_response[0].numpy())), \"responses\"),\n",
    "#     ]\n",
    "# )\n",
    "#     output_schema = Schema([TensorSpec(np.dtype(np.int32),predicted_labels.numpy().shape, 'predicted_labels')])\n",
    "\n",
    "\n",
    "#     signature = ModelSignature(input_schema)\n",
    "\n",
    "\n",
    "#     # Log the model\n",
    "#     mlflow.tensorflow.log_model(model, \"model\", signature=signature,registered_model_name=\"tracking-quickstart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
